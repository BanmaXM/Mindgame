# 模型微调数据集说明

## 数据集概述

本数据集是从三人囚徒困境（3-player Iterated Prisoner's Dilemma）游戏中提取的对话和决策数据，已整理为适合模型微调的格式。数据集包含2887个样本，分为训练集（2309个样本）和验证集（578个样本）。

## 数据格式

数据集提供两种格式：JSON和CSV，每种格式包含以下字段：

### 主要字段
- `instruction`: 指令，描述模型在特定情境下需要执行的任务
- `input`: 输入上下文，包含游戏状态、历史对话和决策信息
- `output`: 期望的模型输出，即模型在给定情境下的回应或决策
- `player_id`: 玩家ID（0、1或2）
- `round`: 游戏轮次（1-5）
- `phase`: 游戏阶段（"chat"或"decision"）
- `model`: 使用的原始模型名称
- `reward`: 该玩家在游戏中的最终奖励
- `agent_type`: 代理类型（"Agent0"、"Agent1"或"Agent2"）
- `agent_prompt`: 代理使用的提示策略

## 数据集文件

- `fine_tuning_data.json`: 完整数据集（JSON格式）
- `fine_tuning_data.csv`: 完整数据集（CSV格式）
- `fine_tuning_data_train.json`: 训练集（JSON格式，80%数据）
- `fine_tuning_data_val.json`: 验证集（JSON格式，20%数据）

## 数据示例

### 聊天阶段示例
```json
{
  "instruction": "You are Player 1 in a 3-player Iterated Prisoner's Dilemma game. Round 1 chat phase. What would you say to other players?",
  "input": "[GAME] You are Player 1 in a 3-player Iterated Prisoner's Dilemma. The match lasts 5 rounds.\nRound structure:\n• 1 free-chat turns\n• 1 decision turn - submit one token per opponent: '[<opp-id> cooperate]' or '[<opp-id> defect]' (i.e. '[1 defect] [2 cooperate]'; the default is 'cooperate'). \nPair-wise payoff matrix (applied to each unordered pair):\n  - Both cooperate  ->  3\n  - Both defect     ->  1\n  - You defect, they cooperate -> 5\n  - You cooperate, they defect -> 0\nThe player(s) with the highest score at the end of all rounds wins.\n\n[GAME] ─── Starting Round 1 ───\tYou can converse freely for the next 1 rounds.\n[Player 0] Hey everyone! Looking forward to a good game together. How's everyone feeling about this round?",
  "output": "Hi all — I'm aiming to cooperate this round to build trust. What are your plans?",
  "player_id": 1,
  "round": 1,
  "phase": "chat",
  "model": "api/openai-gpt-oss-120b",
  "reward": -1.0,
  "agent_type": "Agent1",
  "agent_prompt": "simple_role_play_2"
}
```

### 决策阶段示例
```json
{
  "instruction": "You are Player 0 in a 3-player Iterated Prisoner's Dilemma game. Round 1 decision phase. What are your moves against other players?",
  "input": "[游戏上下文和聊天历史...]",
  "output": "[1 cooperate] [2 cooperate]",
  "player_id": 0,
  "round": 1,
  "phase": "decision",
  "model": "api/openai-gpt-5",
  "reward": -1.0,
  "agent_type": "Agent0",
  "agent_prompt": "2_Fair_Retaliator_0"
}
```

## 微调应用

此数据集可用于微调语言模型，使其在以下方面表现更好：

1. **策略性对话**：学习如何在多玩家环境中进行有效的策略性交流
2. **决策制定**：基于游戏历史和对手行为做出最优决策
3. **角色扮演**：根据不同的提示策略扮演不同类型的玩家
4. **博弈论应用**：理解并应用博弈论原理，如合作、背叛、报复等

## 数据特点

1. **多样性**：数据包含多种不同的策略类型和游戏情境
2. **真实性**：数据来自实际的游戏交互，包含真实的决策和对话
3. **上下文丰富**：每个样本都包含完整的游戏上下文和历史信息
4. **标签完整**：每个样本都标注了玩家ID、轮次、阶段和策略类型等信息

## 使用建议

1. 可以根据需要选择使用JSON或CSV格式
2. 建议使用训练集进行微调，验证集进行性能评估
3. 可以根据具体应用场景筛选特定阶段（chat/decision）或特定策略的数据
4. 对于对话生成任务，可以重点关注chat阶段的数据
5. 对于决策制定任务，可以重点关注decision阶段的数据

## 数据转换脚本

数据转换脚本 `convert_to_finetuning_format.py` 提供了以下功能：
- 从原始游戏数据中提取对话和决策样本
- 创建适合微调的数据格式
- 自动分割训练集和验证集
- 支持多种输出格式（JSON和CSV）

如需重新处理数据或调整参数，可以修改并运行此脚本。